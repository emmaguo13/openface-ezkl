{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from deepface.modules import verification\n",
    "import numpy as np\n",
    "\n",
    "from deepface.models.FacialRecognition import FacialRecognition\n",
    "import cv2\n",
    "\n",
    "import ezkl\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "from onnx2torch import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"OpenFace\"\n",
    "model: FacialRecognition = DeepFace.build_model(model_name)\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model.model)\n",
    "onnx.save(onnx_model, \"openface_new.onnx\")\n",
    "pytorch_model = convert(onnx_model)\n",
    "\n",
    "pytorch_model.eval()\n",
    "\n",
    "target_size = model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = DeepFace.extract_faces(img_path=\"emmapassport.png\")[0][\"face\"]\n",
    "img1 = cv2.resize(img1, target_size)\n",
    "img1 = np.expand_dims(img1, axis=0)  # to (1, 224, 224, 3)\n",
    "\n",
    "img1_torch = torch.tensor(img1, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(pytorch_model,               # model being run\n",
    "                      img1_torch,                   # model input (or a tuple for multiple inputs)\n",
    "                      \"openface_pt.onnx\",            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = (img1).reshape([-1]).tolist()\n",
    "data = dict(input_data = [data_array])\n",
    "data_path = os.path.join('input.json')\n",
    "settings_path = os.path.join('settings.json')\n",
    "model_path = os.path.join('openface_pt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"private\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"fixed\" # private by default\n",
    "\n",
    "# What is the settings file?\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future pending cb=[<builtins.PyDoneCallback object at 0x2991fa210>()]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_path = os.path.join(\"calibration.json\")\n",
    "\n",
    "img1 = DeepFace.extract_faces(img_path=\"kayleepassport.jpg\")[0][\"face\"]\n",
    "img1 = cv2.resize(img1, target_size)\n",
    "img1 = np.expand_dims(img1, axis=0)  # to (1, 224, 224, 3)\n",
    "\n",
    "data_array = (img1).reshape([-1]).tolist()\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "ezkl.calibrate_settings(cal_path, model_path, settings_path, target=\"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model_path = os.path.join('network.compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srs path\n",
    "res = await ezkl.get_srs( settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate the witness file \n",
    "witness_path = os.path.join('witness.json')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "\n",
    "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "assert os.path.isfile(witness_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PanicException",
     "evalue": "dynamic lookup or shuffle should only have one block",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# HERE WE SETUP THE CIRCUIT PARAMS\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# WE GOT KEYS\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# WE GOT CIRCUIT PARAMETERS\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mezkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiled_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvk_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpk_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(vk_path)\n",
      "\u001b[0;31mPanicException\u001b[0m: dynamic lookup or shuffle should only have one block"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 9 columns for non-linearity table.\n",
      "Using 9 columns for non-linearity table.\n",
      "Using 9 columns for non-linearity table.\n",
      "Using 9 columns for non-linearity table.\n",
      "Using 9 columns for non-linearity table.\n",
      "Using 9 columns for non-linearity table.\n",
      "calibration failed extended k is too large to accommodate the quotient polynomial with logrows 20\n",
      "circuit creation from run args failed: SigBitTruncationError\n",
      "circuit creation from run args failed: SigBitTruncationError\n",
      "calibration failed max lookup input (-149327430, 702515025) is too large\n",
      "calibration failed max lookup input (-79466365611640, 3105515024213904) is too large\n",
      "calibration failed max lookup input (-124884517, 426728673) is too large\n",
      "circuit creation from run args failed: SigBitTruncationError\n",
      "circuit creation from run args failed: SigBitTruncationError\n",
      "calibration failed max lookup input (-597492157, 2809742049) is too large\n",
      "calibration failed max lookup input (-1271046503070882, 49728719912394384) is too large\n",
      "calibration failed max lookup input (-499767648, 1706561280) is too large\n",
      "circuit creation from run args failed: SigBitTruncationError\n",
      "circuit creation from run args failed: SigBitTruncationError\n"
     ]
    }
   ],
   "source": [
    "# HERE WE SETUP THE CIRCUIT PARAMS\n",
    "# WE GOT KEYS\n",
    "# WE GOT CIRCUIT PARAMETERS\n",
    "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "\n",
    "\n",
    "\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        \n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
